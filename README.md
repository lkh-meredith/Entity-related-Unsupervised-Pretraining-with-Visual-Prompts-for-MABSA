# Entity-related-Unsupervised-Pretraining-with-Visual-Prompts-for-MABSA
The code of our paper "Entity-related Unsupervised Pretraining with Visual Prompts for Multimodal Aspect-based Sentiment Analysis"

## Data Download
The MABSA dataset can be derived from the paper: Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis (https://github.com/NUSTM/VLP-MABSA)

The pre-training dataset is split from the COCO2014: https://cocodataset.org/ 

The [] is used to split COCO2014 for pre-training.

##
