# Entity-related-Unsupervised-Pretraining-with-Visual-Prompts-for-MABSA
The code of our paper "Entity-related Unsupervised Pretraining with Visual Prompts for Multimodal Aspect-based Sentiment Analysis"

## Data Download
The MABSA dataset can be derived from the paper: Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis (https://github.com/NUSTM/VLP-MABSA)

The pre-training dataset can download from the COCO2014: https://cocodataset.org/

The [split_coco.py](https://github.com/lkh-meredith/Entity-related-Unsupervised-Pretraining-with-Visual-Prompts-for-MABSA/blob/main/split_coco.py) is used to split COCO2014 for pre-training.

##
